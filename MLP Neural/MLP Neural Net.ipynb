{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset with size: | train (69600L, 10L) | test (17400L, 10L) | \n"
     ]
    }
   ],
   "source": [
    "!python preprocess_data.py -i data.csv -o dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the sensor data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load the OPPORTUNITY processed dataset. Sensor data is segmented using a sliding window of fixed length. The class associated with each segment corresponds to the gesture which has been observed during that interval. Given a sliding window of length T, we choose the class of the sequence as the label at t=T, or in other words, the label of last sample in the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = file(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file dataset.data\n",
      " ..reading instances: train (69600L, 10L), test (17400L, 10L)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('dataset.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conc_x = np.concatenate(X_train[0:15, :])\n",
    "for i in range(15, X_train.shape[0], 15):\n",
    "    first_conc_x = np.vstack((first_conc_x, np.concatenate(X_train[i:(i+15), :])))\n",
    "X_train_mlp = first_conc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conc_y = np.unique(y_train[0:15])[0]\n",
    "for i in range(15, y_train.shape[0], 15):\n",
    "    first_conc_y = np.vstack((first_conc_y, np.unique(y_train[i:(i+15)])[0]))\n",
    "y_train_mlp = first_conc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conc_x = np.concatenate(X_test[0:15, :])\n",
    "for i in range(15, X_test.shape[0], 15):\n",
    "    first_conc_x = np.vstack((first_conc_x, np.concatenate(X_test[i:(i+15), :])))\n",
    "X_test_mlp = first_conc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conc_y = np.unique(y_test[0:15])[0]\n",
    "for i in range(15, y_test.shape[0], 15):\n",
    "    first_conc_y = np.vstack((first_conc_y, np.unique(y_test[i:(i+15)])[0]))\n",
    "y_test_mlp = first_conc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mlp.shape[0] == X_train_mlp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mlp.shape[0] == X_test_mlp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=300, alpha=0.0001,\n",
    "                     solver='sgd', verbose=1, random_state=21, tol=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.39514149\n",
      "Iteration 2, loss = 1.23505313\n",
      "Iteration 3, loss = 1.14674317\n",
      "Iteration 4, loss = 1.07030619\n",
      "Iteration 5, loss = 1.00199055\n",
      "Iteration 6, loss = 0.93749833\n",
      "Iteration 7, loss = 0.87684962\n",
      "Iteration 8, loss = 0.82123448\n",
      "Iteration 9, loss = 0.77208114\n",
      "Iteration 10, loss = 0.73010963\n",
      "Iteration 11, loss = 0.69006401\n",
      "Iteration 12, loss = 0.65411497\n",
      "Iteration 13, loss = 0.62000622\n",
      "Iteration 14, loss = 0.58724910\n",
      "Iteration 15, loss = 0.55512142\n",
      "Iteration 16, loss = 0.52527449\n",
      "Iteration 17, loss = 0.49703764\n",
      "Iteration 18, loss = 0.46928826\n",
      "Iteration 19, loss = 0.44337329\n",
      "Iteration 20, loss = 0.41912620\n",
      "Iteration 21, loss = 0.39701737\n",
      "Iteration 22, loss = 0.37745815\n",
      "Iteration 23, loss = 0.35888171\n",
      "Iteration 24, loss = 0.34178157\n",
      "Iteration 25, loss = 0.32681061\n",
      "Iteration 26, loss = 0.31210744\n",
      "Iteration 27, loss = 0.29941361\n",
      "Iteration 28, loss = 0.28816790\n",
      "Iteration 29, loss = 0.27739736\n",
      "Iteration 30, loss = 0.26771825\n",
      "Iteration 31, loss = 0.26033256\n",
      "Iteration 32, loss = 0.25229133\n",
      "Iteration 33, loss = 0.24517600\n",
      "Iteration 34, loss = 0.23874186\n",
      "Iteration 35, loss = 0.23266335\n",
      "Iteration 36, loss = 0.22753405\n",
      "Iteration 37, loss = 0.22200423\n",
      "Iteration 38, loss = 0.21815230\n",
      "Iteration 39, loss = 0.21292658\n",
      "Iteration 40, loss = 0.20876348\n",
      "Iteration 41, loss = 0.20474727\n",
      "Iteration 42, loss = 0.20048826\n",
      "Iteration 43, loss = 0.19716748\n",
      "Iteration 44, loss = 0.19407771\n",
      "Iteration 45, loss = 0.19030635\n",
      "Iteration 46, loss = 0.18689793\n",
      "Iteration 47, loss = 0.18499483\n",
      "Iteration 48, loss = 0.18241515\n",
      "Iteration 49, loss = 0.17915138\n",
      "Iteration 50, loss = 0.17630740\n",
      "Iteration 51, loss = 0.17409055\n",
      "Iteration 52, loss = 0.17146385\n",
      "Iteration 53, loss = 0.16953539\n",
      "Iteration 54, loss = 0.16677001\n",
      "Iteration 55, loss = 0.16459162\n",
      "Iteration 56, loss = 0.16245711\n",
      "Iteration 57, loss = 0.16028698\n",
      "Iteration 58, loss = 0.15827742\n",
      "Iteration 59, loss = 0.15618785\n",
      "Iteration 60, loss = 0.15434173\n",
      "Iteration 61, loss = 0.15226473\n",
      "Iteration 62, loss = 0.15148983\n",
      "Iteration 63, loss = 0.14938685\n",
      "Iteration 64, loss = 0.14799587\n",
      "Iteration 65, loss = 0.14542055\n",
      "Iteration 66, loss = 0.14431465\n",
      "Iteration 67, loss = 0.14230805\n",
      "Iteration 68, loss = 0.14101704\n",
      "Iteration 69, loss = 0.13974244\n",
      "Iteration 70, loss = 0.13782366\n",
      "Iteration 71, loss = 0.13620518\n",
      "Iteration 72, loss = 0.13486398\n",
      "Iteration 73, loss = 0.13322487\n",
      "Iteration 74, loss = 0.13159349\n",
      "Iteration 75, loss = 0.12998942\n",
      "Iteration 76, loss = 0.12870602\n",
      "Iteration 77, loss = 0.12772620\n",
      "Iteration 78, loss = 0.12626793\n",
      "Iteration 79, loss = 0.12485023\n",
      "Iteration 80, loss = 0.12367214\n",
      "Iteration 81, loss = 0.12336391\n",
      "Iteration 82, loss = 0.12068884\n",
      "Iteration 83, loss = 0.11945432\n",
      "Iteration 84, loss = 0.11850903\n",
      "Iteration 85, loss = 0.11789582\n",
      "Iteration 86, loss = 0.11604658\n",
      "Iteration 87, loss = 0.11559173\n",
      "Iteration 88, loss = 0.11396539\n",
      "Iteration 89, loss = 0.11287320\n",
      "Iteration 90, loss = 0.11205544\n",
      "Iteration 91, loss = 0.11069999\n",
      "Iteration 92, loss = 0.10962229\n",
      "Iteration 93, loss = 0.10872035\n",
      "Iteration 94, loss = 0.10720684\n",
      "Iteration 95, loss = 0.10651134\n",
      "Iteration 96, loss = 0.10505971\n",
      "Iteration 97, loss = 0.10403494\n",
      "Iteration 98, loss = 0.10454743\n",
      "Iteration 99, loss = 0.10235217\n",
      "Iteration 100, loss = 0.10149009\n",
      "Iteration 101, loss = 0.10083671\n",
      "Iteration 102, loss = 0.09895391\n",
      "Iteration 103, loss = 0.09993663\n",
      "Iteration 104, loss = 0.09760924\n",
      "Iteration 105, loss = 0.09686458\n",
      "Iteration 106, loss = 0.09557022\n",
      "Iteration 107, loss = 0.09459104\n",
      "Iteration 108, loss = 0.09429333\n",
      "Iteration 109, loss = 0.09384044\n",
      "Iteration 110, loss = 0.09329677\n",
      "Iteration 111, loss = 0.09141011\n",
      "Iteration 112, loss = 0.09058207\n",
      "Iteration 113, loss = 0.09029230\n",
      "Iteration 114, loss = 0.08894328\n",
      "Iteration 115, loss = 0.08837281\n",
      "Iteration 116, loss = 0.08719183\n",
      "Iteration 117, loss = 0.08638012\n",
      "Iteration 118, loss = 0.08576717\n",
      "Iteration 119, loss = 0.08497105\n",
      "Iteration 120, loss = 0.08404773\n",
      "Iteration 121, loss = 0.08393844\n",
      "Iteration 122, loss = 0.08306965\n",
      "Iteration 123, loss = 0.08229425\n",
      "Iteration 124, loss = 0.08136418\n",
      "Iteration 125, loss = 0.08087676\n",
      "Iteration 126, loss = 0.08010117\n",
      "Iteration 127, loss = 0.07965100\n",
      "Iteration 128, loss = 0.07841966\n",
      "Iteration 129, loss = 0.07813764\n",
      "Iteration 130, loss = 0.07783030\n",
      "Iteration 131, loss = 0.07701210\n",
      "Iteration 132, loss = 0.07582734\n",
      "Iteration 133, loss = 0.07571397\n",
      "Iteration 134, loss = 0.07439367\n",
      "Iteration 135, loss = 0.07404075\n",
      "Iteration 136, loss = 0.07414250\n",
      "Iteration 137, loss = 0.07248857\n",
      "Iteration 138, loss = 0.07213263\n",
      "Iteration 139, loss = 0.07227509\n",
      "Iteration 140, loss = 0.07097262\n",
      "Iteration 141, loss = 0.07055285\n",
      "Iteration 142, loss = 0.06958248\n",
      "Iteration 143, loss = 0.06943062\n",
      "Iteration 144, loss = 0.06878099\n",
      "Iteration 145, loss = 0.06809693\n",
      "Iteration 146, loss = 0.06757295\n",
      "Iteration 147, loss = 0.06707539\n",
      "Iteration 148, loss = 0.06619480\n",
      "Iteration 149, loss = 0.06580401\n",
      "Iteration 150, loss = 0.06610149\n",
      "Iteration 151, loss = 0.06453265\n",
      "Iteration 152, loss = 0.06377198\n",
      "Iteration 153, loss = 0.06354185\n",
      "Iteration 154, loss = 0.06335544\n",
      "Iteration 155, loss = 0.06262550\n",
      "Iteration 156, loss = 0.06226655\n",
      "Iteration 157, loss = 0.06155234\n",
      "Iteration 158, loss = 0.06139545\n",
      "Iteration 159, loss = 0.06049581\n",
      "Iteration 160, loss = 0.06025125\n",
      "Iteration 161, loss = 0.05974423\n",
      "Iteration 162, loss = 0.05879506\n",
      "Iteration 163, loss = 0.05884987\n",
      "Iteration 164, loss = 0.05831446\n",
      "Iteration 165, loss = 0.05789096\n",
      "Iteration 166, loss = 0.05735512\n",
      "Iteration 167, loss = 0.05670961\n",
      "Iteration 168, loss = 0.05679272\n",
      "Iteration 169, loss = 0.05585810\n",
      "Iteration 170, loss = 0.05538398\n",
      "Iteration 171, loss = 0.05491692\n",
      "Iteration 172, loss = 0.05482836\n",
      "Iteration 173, loss = 0.05398238\n",
      "Iteration 174, loss = 0.05403396\n",
      "Iteration 175, loss = 0.05332597\n",
      "Iteration 176, loss = 0.05255364\n",
      "Iteration 177, loss = 0.05251207\n",
      "Iteration 178, loss = 0.05355138\n",
      "Iteration 179, loss = 0.05139126\n",
      "Iteration 180, loss = 0.05145113\n",
      "Iteration 181, loss = 0.05141959\n",
      "Iteration 182, loss = 0.05052455\n",
      "Iteration 183, loss = 0.05038764\n",
      "Iteration 184, loss = 0.04956336\n",
      "Iteration 185, loss = 0.04952992\n",
      "Iteration 186, loss = 0.04901101\n",
      "Iteration 187, loss = 0.04846183\n",
      "Iteration 188, loss = 0.04820413\n",
      "Iteration 189, loss = 0.04801820\n",
      "Iteration 190, loss = 0.04744950\n",
      "Iteration 191, loss = 0.04735355\n",
      "Iteration 192, loss = 0.04681351\n",
      "Iteration 193, loss = 0.04632998\n",
      "Iteration 194, loss = 0.04623297\n",
      "Iteration 195, loss = 0.04598493\n",
      "Iteration 196, loss = 0.04557922\n",
      "Iteration 197, loss = 0.04570531\n",
      "Iteration 198, loss = 0.04476966\n",
      "Iteration 199, loss = 0.04463661\n",
      "Iteration 200, loss = 0.04421622\n",
      "Iteration 201, loss = 0.04410629\n",
      "Iteration 202, loss = 0.04407908\n",
      "Iteration 203, loss = 0.04306850\n",
      "Iteration 204, loss = 0.04295733\n",
      "Iteration 205, loss = 0.04261701\n",
      "Iteration 206, loss = 0.04225278\n",
      "Iteration 207, loss = 0.04263502\n",
      "Iteration 208, loss = 0.04184127\n",
      "Iteration 209, loss = 0.04136594\n",
      "Iteration 210, loss = 0.04122794\n",
      "Iteration 211, loss = 0.04089521\n",
      "Iteration 212, loss = 0.04066905\n",
      "Iteration 213, loss = 0.04023106\n",
      "Iteration 214, loss = 0.03998268\n",
      "Iteration 215, loss = 0.04001431\n",
      "Iteration 216, loss = 0.03947706\n",
      "Iteration 217, loss = 0.03921135\n",
      "Iteration 218, loss = 0.03907404\n",
      "Iteration 219, loss = 0.03869854\n",
      "Iteration 220, loss = 0.03867481\n",
      "Iteration 221, loss = 0.03834459\n",
      "Iteration 222, loss = 0.03833414\n",
      "Iteration 223, loss = 0.03773739\n",
      "Iteration 224, loss = 0.03758461\n",
      "Iteration 225, loss = 0.03769052\n",
      "Iteration 226, loss = 0.03691307\n",
      "Iteration 227, loss = 0.03719981\n",
      "Iteration 228, loss = 0.03656824\n",
      "Iteration 229, loss = 0.03652879\n",
      "Iteration 230, loss = 0.03631980\n",
      "Iteration 231, loss = 0.03580545\n",
      "Iteration 232, loss = 0.03558345\n",
      "Iteration 233, loss = 0.03501347\n",
      "Iteration 234, loss = 0.03561642\n",
      "Iteration 235, loss = 0.03494117\n",
      "Iteration 236, loss = 0.03485916\n",
      "Iteration 237, loss = 0.03464939\n",
      "Iteration 238, loss = 0.03422907\n",
      "Iteration 239, loss = 0.03415058\n",
      "Iteration 240, loss = 0.03370421\n",
      "Iteration 241, loss = 0.03375784\n",
      "Iteration 242, loss = 0.03322772\n",
      "Iteration 243, loss = 0.03298399\n",
      "Iteration 244, loss = 0.03286222\n",
      "Iteration 245, loss = 0.03269210\n",
      "Iteration 246, loss = 0.03257541\n",
      "Iteration 247, loss = 0.03272317\n",
      "Iteration 248, loss = 0.03192602\n",
      "Iteration 249, loss = 0.03173986\n",
      "Iteration 250, loss = 0.03174272\n",
      "Iteration 251, loss = 0.03199391\n",
      "Iteration 252, loss = 0.03103507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.03150856\n",
      "Iteration 254, loss = 0.03074371\n",
      "Iteration 255, loss = 0.03118407\n",
      "Iteration 256, loss = 0.03056706\n",
      "Iteration 257, loss = 0.03035672\n",
      "Iteration 258, loss = 0.03020003\n",
      "Iteration 259, loss = 0.02985763\n",
      "Iteration 260, loss = 0.02988319\n",
      "Iteration 261, loss = 0.02933314\n",
      "Iteration 262, loss = 0.02943504\n",
      "Iteration 263, loss = 0.02926089\n",
      "Iteration 264, loss = 0.02911493\n",
      "Iteration 265, loss = 0.02923029\n",
      "Iteration 266, loss = 0.03045211\n",
      "Iteration 267, loss = 0.02873045\n",
      "Iteration 268, loss = 0.02856891\n",
      "Iteration 269, loss = 0.02813155\n",
      "Iteration 270, loss = 0.02795313\n",
      "Iteration 271, loss = 0.02831821\n",
      "Iteration 272, loss = 0.02768791\n",
      "Iteration 273, loss = 0.02756695\n",
      "Iteration 274, loss = 0.02749160\n",
      "Iteration 275, loss = 0.02701242\n",
      "Iteration 276, loss = 0.02717625\n",
      "Iteration 277, loss = 0.02696973\n",
      "Iteration 278, loss = 0.02666495\n",
      "Iteration 279, loss = 0.02669303\n",
      "Iteration 280, loss = 0.02681484\n",
      "Iteration 281, loss = 0.02630378\n",
      "Iteration 282, loss = 0.02596486\n",
      "Iteration 283, loss = 0.02603425\n",
      "Iteration 284, loss = 0.02588986\n",
      "Iteration 285, loss = 0.02577687\n",
      "Iteration 286, loss = 0.02566739\n",
      "Iteration 287, loss = 0.02531596\n",
      "Iteration 288, loss = 0.02585242\n",
      "Iteration 289, loss = 0.02497681\n",
      "Iteration 290, loss = 0.02514498\n",
      "Iteration 291, loss = 0.02497696\n",
      "Iteration 292, loss = 0.02455242\n",
      "Iteration 293, loss = 0.02456919\n",
      "Iteration 294, loss = 0.02442299\n",
      "Iteration 295, loss = 0.02418317\n",
      "Iteration 296, loss = 0.02411204\n",
      "Iteration 297, loss = 0.02394876\n",
      "Iteration 298, loss = 0.02386973\n",
      "Iteration 299, loss = 0.02382225\n",
      "Iteration 300, loss = 0.02379585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=21, shuffle=True,\n",
       "       solver='sgd', tol=1e-09, validation_fraction=0.1, verbose=1,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_mlp, y_train_mlp.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = clf.predict(X_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844827586206897"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_mlp.flatten(), y_pred_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cPickle as cp\n",
    "from io import BytesIO\n",
    "from pandas import Series\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('testdata.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_SENSOR_CHANNELS = 10\n",
    "\n",
    "NORM_MAX_THRESHOLDS = [200, 200, 200, 250000, 250000, 250000, 100, 100, 100, 100]\n",
    "\n",
    "NORM_MIN_THRESHOLDS = [-200, -200, -200, -250000, -250000, -250000, -100, -100, -100, -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, max_list, min_list):\n",
    "    max_list, min_list = np.array(max_list), np.array(min_list)\n",
    "    diffs = max_list - min_list\n",
    "    for i in np.arange(data.shape[1]):\n",
    "        data[:, i] = (data[:, i]-min_list[i])/diffs[i]\n",
    "    data[data > 1] = 0.99\n",
    "    data[data < 0] = 0.00\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_file(dataset):\n",
    "    # Colums are segmentd into features and labels\n",
    "    data_x = dataset[:,2:12]\n",
    "\n",
    "    # Perform linear interpolation\n",
    "    data_x = np.array([Series(i).interpolate() for i in data_x.T]).T\n",
    "\n",
    "    # Remaining missing data are converted to zero\n",
    "    data_x[np.isnan(data_x)] = 0\n",
    "\n",
    "    # All sensor channels are normalized\n",
    "    data_x = normalize(data_x, NORM_MAX_THRESHOLDS, NORM_MIN_THRESHOLDS)\n",
    "\n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data):\n",
    "    data_x = np.empty((0, 10))\n",
    "    x = process_dataset_file(data)\n",
    "    data_x = np.vstack((data_x, x))\n",
    "\n",
    "    return data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_conc_x = np.concatenate(test_data[0:15, :])\n",
    "for i in range(15, test_data.shape[0], 15):\n",
    "    first_conc_x = np.vstack((first_conc_x, np.concatenate(test_data[i:(i+15), :])))\n",
    "test_data_mlp = first_conc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_data_mlp).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
